{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyM4HmMb1LbtSTutxJbb0Zji"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NJMA0skl0iob","executionInfo":{"status":"ok","timestamp":1764859537700,"user_tz":-330,"elapsed":9071,"user":{"displayName":"22bd1a056g","userId":"12822488165018302407"}},"outputId":"a06b6c20-cb04-44fe-9ce8-e13be261c944"},"outputs":[{"output_type":"stream","name":"stdout","text":["Num GPUs Available:  1\n"]}],"source":["import tensorflow as tf\n","import numpy as np\n","import requests\n","\n","# Check if GPU is available (This confirms Colab is set up right)\n","print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"]},{"cell_type":"code","source":["# --- Data Collection ---\n","# We will download 'The Adventures of Sherlock Holmes' from Project Gutenberg\n","url = \"https://www.gutenberg.org/files/1661/1661-0.txt\"\n","\n","response = requests.get(url)\n","text_data = response.text\n","\n","# Quick verification\n","print(\"------------------------------------------------\")\n","print(f\"Data Downloaded Successfully!\")\n","print(f\"Total characters in dataset: {len(text_data)}\")\n","print(\"------------------------------------------------\")\n","print(\"First 500 characters preview:\\n\")\n","print(text_data[:500])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XsGqWyS-0y0D","executionInfo":{"status":"ok","timestamp":1764859545237,"user_tz":-330,"elapsed":2112,"user":{"displayName":"22bd1a056g","userId":"12822488165018302407"}},"outputId":"8357b3df-f9a5-4366-f3e8-a39528772c1c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["------------------------------------------------\n","Data Downloaded Successfully!\n","Total characters in dataset: 593731\n","------------------------------------------------\n","First 500 characters preview:\n","\n","﻿The Project Gutenberg eBook of The Adventures of Sherlock Holmes,\r\n","by Arthur Conan Doyle\r\n","\r\n","This eBook is for the use of anyone anywhere in the United States and\r\n","most other parts of the world at no cost and with almost no restrictions\r\n","whatsoever. You may copy it, give it away or re-use it under the terms\r\n","of the Project Gutenberg License included with this eBook or online at\r\n","www.gutenberg.org. If you are not located in the United States, you\r\n","will have to check the laws of the country where \n"]}]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.text import Tokenizer\n","import numpy as np"],"metadata":{"id":"nREWXNsu033T","executionInfo":{"status":"ok","timestamp":1764859640344,"user_tz":-330,"elapsed":4,"user":{"displayName":"22bd1a056g","userId":"12822488165018302407"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# --- 1. Text Cleaning ---\n","# Remove the Gutenberg Header/Footer to get the actual story\n","# We look for the start of the first story roughly\n","start_marker = \"SCANDAL IN BOHEMIA\"\n","start_index = text_data.find(start_marker)\n","\n","# If found, slice the text. If not, just use the whole thing.\n","if start_index != -1:\n","    corpus = text_data[start_index:]\n","else:\n","    corpus = text_data\n","\n","# Split the huge text into a list of sentences/lines\n","corpus = corpus.lower().split(\"\\n\")"],"metadata":{"id":"5R9cWDKE1PmT","executionInfo":{"status":"ok","timestamp":1764859642216,"user_tz":-330,"elapsed":11,"user":{"displayName":"22bd1a056g","userId":"12822488165018302407"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# --- 2. Tokenization ---\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(corpus) # Creates the vocabulary\n","\n","total_words = len(tokenizer.word_index) + 1 # +1 is required for padding later\n","\n","print(f\"Total unique words (Vocabulary Size): {total_words}\")\n","print(f\"Total lines of text to process: {len(corpus)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e1DDtYN41QDU","executionInfo":{"status":"ok","timestamp":1764859667732,"user_tz":-330,"elapsed":142,"user":{"displayName":"22bd1a056g","userId":"12822488165018302407"}},"outputId":"29fd3acd-4545-4cd5-dc39-014c18dff416"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Total unique words (Vocabulary Size): 10229\n","Total lines of text to process: 12254\n"]}]},{"cell_type":"code","source":["# --- 3. Create N-gram Sequences (The Logic) ---\n","input_sequences = []\n","\n","for line in corpus:\n","    token_list = tokenizer.texts_to_sequences([line])[0]\n","    # We only care about lines that have at least 2 words\n","    for i in range(1, len(token_list)):\n","        n_gram_sequence = token_list[:i+1]\n","        input_sequences.append(n_gram_sequence)"],"metadata":{"id":"iJcYYe4q1WPz","executionInfo":{"status":"ok","timestamp":1764859682678,"user_tz":-330,"elapsed":540,"user":{"displayName":"22bd1a056g","userId":"12822488165018302407"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["print(f\"Total Input Sequences created: {len(input_sequences)}\")\n","print(\"Example sequence (numbers):\", input_sequences[0])\n","print(\"Example sequence (words):\", [tokenizer.index_word[idx] for idx in input_sequences[0]])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xWJJ4rIE1ZzM","executionInfo":{"status":"ok","timestamp":1764859699590,"user_tz":-330,"elapsed":35,"user":{"displayName":"22bd1a056g","userId":"12822488165018302407"}},"outputId":"ef0754f5-cfa4-4cdd-f100-0a3a0bc689dc"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Total Input Sequences created: 102787\n","Example sequence (numbers): [982, 8]\n","Example sequence (words): ['scandal', 'in']\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import numpy as np"],"metadata":{"id":"Oq0VL7Mq1eD0","executionInfo":{"status":"ok","timestamp":1764859847458,"user_tz":-330,"elapsed":36,"user":{"displayName":"22bd1a056g","userId":"12822488165018302407"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# --- 1. Padding ---\n","# We need to find the longest sentence to ensure all inputs match that size\n","max_sequence_len = max([len(x) for x in input_sequences])\n","print(f\"Longest sequence in the text: {max_sequence_len} words\")\n","\n","# Pad sequences so they are all the same length\n","# 'pre' padding means adding zeros at the START of short sentences\n","input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aAjIGj642CJ9","executionInfo":{"status":"ok","timestamp":1764859867488,"user_tz":-330,"elapsed":193,"user":{"displayName":"22bd1a056g","userId":"12822488165018302407"}},"outputId":"497c1b19-62b0-4ae8-db49-8a43a97cfe9c"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Longest sequence in the text: 20 words\n"]}]},{"cell_type":"code","source":["# --- 2. Create Predictors (X) and Label (y) ---\n","# X = All words EXCEPT the last one\n","# y = The LAST word (the one we want to predict)\n","X, y = input_sequences[:,:-1], input_sequences[:,-1]\n","\n","# Check the shapes to ensure memory is handling it well\n","print(\"------------------------------------------------\")\n","print(f\"Shape of X (Inputs): {X.shape}\")\n","print(f\"Shape of y (Targets): {y.shape}\")\n","print(\"------------------------------------------------\")\n","# Verify the split with an example\n","print(\"Original padded sequence:\", input_sequences[0])\n","print(\"Input (X):\", X[0])\n","print(\"Target (y):\", y[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2L2bHTIW2HAF","executionInfo":{"status":"ok","timestamp":1764859877443,"user_tz":-330,"elapsed":36,"user":{"displayName":"22bd1a056g","userId":"12822488165018302407"}},"outputId":"13576f91-b2f6-46ee-9154-ad1268523a8f"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["------------------------------------------------\n","Shape of X (Inputs): (102787, 19)\n","Shape of y (Targets): (102787,)\n","------------------------------------------------\n","Original padded sequence: [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n"," 982   8]\n","Input (X): [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n"," 982]\n","Target (y): 8\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout"],"metadata":{"id":"Kh4rrHbk2Jen","executionInfo":{"status":"ok","timestamp":1764859967384,"user_tz":-330,"elapsed":35,"user":{"displayName":"22bd1a056g","userId":"12822488165018302407"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# --- Retrieve necessary variables from previous steps ---\n","# input_len is the length of your input sequences (X.shape[1] = 19)\n","input_len = X.shape[1]\n","# total_words is the size of your vocabulary (from Step 2)\n","# Make sure the variable total_words is defined in your Colab session!\n","# total_words = len(tokenizer.word_index) + 1\n","\n","# --- Model Definition ---\n","model = Sequential()\n","\n","# 1. Embedding Layer: Turns word indexes into dense vectors (100 dimensions)\n","# input_dim: Vocabulary size (total_words)\n","# output_dim: Size of the dense vector for each word (100)\n","# input_length: Length of the sequence (19)\n","model.add(Embedding(input_dim=total_words, output_dim=100, input_length=input_len))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QV_3je512fbx","executionInfo":{"status":"ok","timestamp":1764859978716,"user_tz":-330,"elapsed":35,"user":{"displayName":"22bd1a056g","userId":"12822488165018302407"}},"outputId":"9e70d902-bf42-434e-c271-d2561d430b8e"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["# 2. LSTM Layer: The core of the sequence prediction\n","# 150 units is a good starting point for complexity\n","model.add(LSTM(150))\n","model.add(Dropout(0.2)) # Dropout helps prevent overfitting"],"metadata":{"id":"aHPaE9bS2iNB","executionInfo":{"status":"ok","timestamp":1764860004911,"user_tz":-330,"elapsed":41,"user":{"displayName":"22bd1a056g","userId":"12822488165018302407"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# 3. Output Layer: Predicts the next word\n","# units: Must equal the vocabulary size (one neuron for every possible word)\n","# activation='softmax': Converts raw predictions into probabilities\n","model.add(Dense(total_words, activation='softmax'))\n","\n","# --- Compilation (The Crucial Anti-Crash Step) ---\n","# We use 'sparse_categorical_crossentropy' because our labels (y) are integers,\n","# NOT one-hot encoded vectors, saving massive amounts of RAM.\n","model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# Display the model structure\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":257},"id":"LAj7IPVQ2oiH","executionInfo":{"status":"ok","timestamp":1764860015886,"user_tz":-330,"elapsed":52,"user":{"displayName":"22bd1a056g","userId":"12822488165018302407"}},"outputId":"a8cc746a-b005-4b4d-b3a7-461fef75d53c"},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":["# Use a large batch size for GPU efficiency\n","BATCH_SIZE = 256\n","# 50 epochs is a solid goal, but we can stop early if accuracy is high\n","EPOCHS = 50\n","\n","print(\"--- Starting Model Training (Using T4 GPU) ---\")\n","\n","# The model will 'build' itself right before the first epoch\n","history = model.fit(\n","    X,\n","    y,\n","    epochs=EPOCHS,\n","    batch_size=BATCH_SIZE,\n","    verbose=1\n",")\n","\n","print(\"\\n--- Training Complete! ---\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wp5-qdKp2rRX","executionInfo":{"status":"ok","timestamp":1764860307257,"user_tz":-330,"elapsed":236888,"user":{"displayName":"22bd1a056g","userId":"12822488165018302407"}},"outputId":"aa4b7fdd-e35d-438b-f7e6-7ec9ee1a042d"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Starting Model Training (Using T4 GPU) ---\n","Epoch 1/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.0400 - loss: 7.1810\n","Epoch 2/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.0559 - loss: 6.3610\n","Epoch 3/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.0745 - loss: 6.1023\n","Epoch 4/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.1012 - loss: 5.8040\n","Epoch 5/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.1124 - loss: 5.5895\n","Epoch 6/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.1262 - loss: 5.4276\n","Epoch 7/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.1343 - loss: 5.2914\n","Epoch 8/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.1391 - loss: 5.1803\n","Epoch 9/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.1484 - loss: 5.0657\n","Epoch 10/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.1522 - loss: 4.9512\n","Epoch 11/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.1595 - loss: 4.8464\n","Epoch 12/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.1664 - loss: 4.7581\n","Epoch 13/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.1706 - loss: 4.6577\n","Epoch 14/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.1757 - loss: 4.5879\n","Epoch 15/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.1798 - loss: 4.4926\n","Epoch 16/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.1861 - loss: 4.4141\n","Epoch 17/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.1920 - loss: 4.3310\n","Epoch 18/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.1961 - loss: 4.2599\n","Epoch 19/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.2040 - loss: 4.1804\n","Epoch 20/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.2085 - loss: 4.1162\n","Epoch 21/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.2160 - loss: 4.0392\n","Epoch 22/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.2244 - loss: 3.9779\n","Epoch 23/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.2296 - loss: 3.9214\n","Epoch 24/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.2407 - loss: 3.8476\n","Epoch 25/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.2480 - loss: 3.7965\n","Epoch 26/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.2544 - loss: 3.7409\n","Epoch 27/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.2607 - loss: 3.6886\n","Epoch 28/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.2682 - loss: 3.6454\n","Epoch 29/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.2751 - loss: 3.5909\n","Epoch 30/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.2790 - loss: 3.5448\n","Epoch 31/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.2844 - loss: 3.5088\n","Epoch 32/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.2894 - loss: 3.4756\n","Epoch 33/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.2968 - loss: 3.4263\n","Epoch 34/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.3031 - loss: 3.3840\n","Epoch 35/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.3089 - loss: 3.3397\n","Epoch 36/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.3150 - loss: 3.2996\n","Epoch 37/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.3193 - loss: 3.2747\n","Epoch 38/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.3200 - loss: 3.2477\n","Epoch 39/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.3291 - loss: 3.2053\n","Epoch 40/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.3337 - loss: 3.1629\n","Epoch 41/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.3393 - loss: 3.1493\n","Epoch 42/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.3414 - loss: 3.1194\n","Epoch 43/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.3474 - loss: 3.0832\n","Epoch 44/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.3508 - loss: 3.0530\n","Epoch 45/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.3544 - loss: 3.0266\n","Epoch 46/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.3643 - loss: 2.9825\n","Epoch 47/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.3633 - loss: 2.9709\n","Epoch 48/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.3679 - loss: 2.9500\n","Epoch 49/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.3700 - loss: 2.9221\n","Epoch 50/50\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.3756 - loss: 2.8985\n","\n","--- Training Complete! ---\n"]}]},{"cell_type":"code","source":["# Use the high-level Keras saving function\n","model.save(\"next_word_predictor.h5\")\n","print(\"Model saved as next_word_predictor.h5\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wqP8Lhj524kd","executionInfo":{"status":"ok","timestamp":1764860586242,"user_tz":-330,"elapsed":109,"user":{"displayName":"22bd1a056g","userId":"12822488165018302407"}},"outputId":"1168cc7f-5767-480c-89c9-26946e25e27e"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["Model saved as next_word_predictor.h5\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import numpy as np\n","\n","def predict_next_word(seed_text, n_words=1):\n","    \"\"\"\n","    Predicts the next n_words given a seed text.\n","    \"\"\"\n","    # X.shape[1] is the input length (19 in your case)\n","    input_len = X.shape[1]\n","\n","    for _ in range(n_words):\n","        # 1. Prepare the seed text (using the same tokenizer)\n","        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n","\n","        # 2. Pad the sequence to match the model's input length (19)\n","        padded_token_list = pad_sequences([token_list], maxlen=input_len, padding='pre')\n","\n","        # 3. Predict the word probabilities\n","        # We use model.predict() which outputs an array of probabilities for all ~9k words\n","        predicted_probs = model.predict(padded_token_list, verbose=0)\n","\n","        # 4. Get the index of the word with the highest probability\n","        predicted_index = np.argmax(predicted_probs, axis=-1)[0]\n","\n","        # 5. Convert index back to word\n","        output_word = \"\"\n","        if predicted_index in tokenizer.index_word:\n","            output_word = tokenizer.index_word[predicted_index]\n","\n","        # 6. Append the predicted word to the seed text for the next prediction loop\n","        seed_text += \" \" + output_word\n","\n","    return seed_text.title()\n","\n","# --- Test Cases ---\n","\n","print(\"\\n--- Model Predictions (Accuracy 37.56%) ---\")\n","\n","# Test 1: Common phrase in the book\n","seed1 = \"holmes was sitting upon\"\n","print(f\"Input: '{seed1}'\\nPrediction: {predict_next_word(seed1, 3)}\\n\")\n","\n","# Test 2: Phrase to test grammar and context\n","seed2 = \"the dog runs after the\"\n","print(f\"Input: '{seed2}'\\nPrediction: {predict_next_word(seed2, 2)}\\n\")\n","\n","# Test 3: Phrase to test common names\n","seed3 = \"my dear watson\"\n","print(f\"Input: '{seed3}'\\nPrediction: {predict_next_word(seed3, 5)}\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vuDfwyla42gV","executionInfo":{"status":"ok","timestamp":1764860603588,"user_tz":-330,"elapsed":594,"user":{"displayName":"22bd1a056g","userId":"12822488165018302407"}},"outputId":"a1d57d92-8f66-4943-c508-266023a8985e"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Model Predictions (Accuracy 37.56%) ---\n","Input: 'holmes was sitting upon'\n","Prediction: Holmes Was Sitting Upon The Door And\n","\n","Input: 'the dog runs after the'\n","Prediction: The Dog Runs After The Other Side\n","\n","Input: 'my dear watson'\n","Prediction: My Dear Watson ” Said Holmes “This Is\n","\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n","# Import these again just in case the Colab session lost them\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import numpy as np\n","\n","# --- Define the NEW Bi-LSTM Model ---\n","# We use a new variable name (new_model) to avoid overwriting the old 'model'.\n","new_model = Sequential()\n","\n","# 1. Embedding Layer: Increased output_dim to 150 (slightly higher quality vectors)\n","# We use X.shape[1] (19) for input_length\n","new_model.add(Embedding(input_dim=total_words, output_dim=150, input_length=X.shape[1]))\n","\n","# 2. Bi-LSTM Layer (The Major Improvement)\n","# Bi-LSTM processes the sequence both forward and backward, enhancing context.\n","# We use 256 units for increased model capacity.\n","new_model.add(Bidirectional(LSTM(256)))\n","new_model.add(Dropout(0.3)) # Slightly increased dropout for regularization\n","\n","# 3. Output Layer (Same as before)\n","new_model.add(Dense(total_words, activation='softmax'))\n","\n","# --- Compilation (Anti-Crash Strategy Maintained) ---\n","# Must use 'sparse_categorical_crossentropy' since 'y' is integers.\n","new_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","print(\"--- New Bi-LSTM Model Architecture ---\")\n","new_model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":274},"id":"vvlNE1-446mm","executionInfo":{"status":"ok","timestamp":1764860769635,"user_tz":-330,"elapsed":51,"user":{"displayName":"22bd1a056g","userId":"12822488165018302407"}},"outputId":"0aeed85d-d8d9-46c5-ac0e-b397a81bbf29"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["--- New Bi-LSTM Model Architecture ---\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential_1\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":["# Train for 100 epochs (Monitor this and stop if accuracy plateaus)\n","BATCH_SIZE = 256\n","NEW_EPOCHS = 100\n","\n","print(\"--- Starting Bi-LSTM Model Training (100 Epochs) ---\")\n","\n","history_new = new_model.fit(\n","    X,\n","    y,\n","    epochs=NEW_EPOCHS,\n","    batch_size=BATCH_SIZE,\n","    verbose=1\n",")\n","\n","print(\"\\n--- Bi-LSTM Training Complete! ---\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"5UTO85R25jSz","executionInfo":{"status":"ok","timestamp":1764861694655,"user_tz":-330,"elapsed":901659,"user":{"displayName":"22bd1a056g","userId":"12822488165018302407"}},"outputId":"5956a975-f2f0-43c0-8a98-1a63a8c6a169"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Starting Bi-LSTM Model Training (100 Epochs) ---\n","Epoch 1/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.0462 - loss: 7.0147\n","Epoch 2/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.0755 - loss: 6.1579\n","Epoch 3/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.1083 - loss: 5.6878\n","Epoch 4/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.1272 - loss: 5.4082\n","Epoch 5/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.1403 - loss: 5.1525\n","Epoch 6/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.1535 - loss: 4.9306\n","Epoch 7/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.1641 - loss: 4.7156\n","Epoch 8/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.1749 - loss: 4.5461\n","Epoch 9/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.1835 - loss: 4.3688\n","Epoch 10/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.2018 - loss: 4.1951\n","Epoch 11/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.2163 - loss: 4.0419\n","Epoch 12/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.2360 - loss: 3.8813\n","Epoch 13/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.2521 - loss: 3.7467\n","Epoch 14/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.2693 - loss: 3.6050\n","Epoch 15/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.2881 - loss: 3.4877\n","Epoch 16/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.3058 - loss: 3.3478\n","Epoch 17/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.3223 - loss: 3.2449\n","Epoch 18/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.3393 - loss: 3.1411\n","Epoch 19/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.3543 - loss: 3.0315\n","Epoch 20/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.3701 - loss: 2.9418\n","Epoch 21/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.3890 - loss: 2.8285\n","Epoch 22/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.4014 - loss: 2.7388\n","Epoch 23/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.4194 - loss: 2.6461\n","Epoch 24/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.4346 - loss: 2.5569\n","Epoch 25/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.4533 - loss: 2.4582\n","Epoch 26/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.4663 - loss: 2.3795\n","Epoch 27/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.4821 - loss: 2.2882\n","Epoch 28/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.4968 - loss: 2.2211\n","Epoch 29/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.5091 - loss: 2.1447\n","Epoch 30/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.5258 - loss: 2.0676\n","Epoch 31/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.5355 - loss: 2.0097\n","Epoch 32/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.5523 - loss: 1.9297\n","Epoch 33/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.5671 - loss: 1.8499\n","Epoch 34/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.5780 - loss: 1.7929\n","Epoch 35/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.5921 - loss: 1.7322\n","Epoch 36/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.6053 - loss: 1.6661\n","Epoch 37/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.6210 - loss: 1.5967\n","Epoch 38/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.6316 - loss: 1.5416\n","Epoch 39/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.6405 - loss: 1.4951\n","Epoch 40/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.6526 - loss: 1.4435\n","Epoch 41/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.6692 - loss: 1.3787\n","Epoch 42/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.6764 - loss: 1.3374\n","Epoch 43/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.6877 - loss: 1.2870\n","Epoch 44/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.6997 - loss: 1.2341\n","Epoch 45/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.7040 - loss: 1.2054\n","Epoch 46/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.7145 - loss: 1.1626\n","Epoch 47/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.7283 - loss: 1.0973\n","Epoch 48/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.7321 - loss: 1.0811\n","Epoch 49/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.7399 - loss: 1.0466\n","Epoch 50/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.7463 - loss: 1.0173\n","Epoch 51/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.7565 - loss: 0.9813\n","Epoch 52/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.7663 - loss: 0.9385\n","Epoch 53/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.7693 - loss: 0.9237\n","Epoch 54/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.7768 - loss: 0.8954\n","Epoch 55/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.7806 - loss: 0.8718\n","Epoch 56/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.7867 - loss: 0.8502\n","Epoch 57/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.7919 - loss: 0.8274\n","Epoch 58/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.7974 - loss: 0.8086\n","Epoch 59/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.7981 - loss: 0.7921\n","Epoch 60/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8085 - loss: 0.7639\n","Epoch 61/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8089 - loss: 0.7586\n","Epoch 62/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8140 - loss: 0.7365\n","Epoch 63/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8169 - loss: 0.7300\n","Epoch 64/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8194 - loss: 0.7184\n","Epoch 65/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8255 - loss: 0.6916\n","Epoch 66/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8271 - loss: 0.6820\n","Epoch 67/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8288 - loss: 0.6742\n","Epoch 68/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8307 - loss: 0.6669\n","Epoch 69/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8343 - loss: 0.6493\n","Epoch 70/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8347 - loss: 0.6488\n","Epoch 71/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8399 - loss: 0.6253\n","Epoch 72/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8400 - loss: 0.6263\n","Epoch 73/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8452 - loss: 0.6077\n","Epoch 74/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8457 - loss: 0.6061\n","Epoch 75/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8480 - loss: 0.5902\n","Epoch 76/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8515 - loss: 0.5806\n","Epoch 77/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8521 - loss: 0.5738\n","Epoch 78/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8510 - loss: 0.5746\n","Epoch 79/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8531 - loss: 0.5726\n","Epoch 80/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8530 - loss: 0.5710\n","Epoch 81/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8547 - loss: 0.5579\n","Epoch 82/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8593 - loss: 0.5471\n","Epoch 83/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8545 - loss: 0.5610\n","Epoch 84/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8584 - loss: 0.5445\n","Epoch 85/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8637 - loss: 0.5245\n","Epoch 86/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8632 - loss: 0.5278\n","Epoch 87/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8631 - loss: 0.5264\n","Epoch 88/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - accuracy: 0.8649 - loss: 0.5239\n","Epoch 89/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8646 - loss: 0.5184\n","Epoch 90/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8672 - loss: 0.5144\n","Epoch 91/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8692 - loss: 0.5073\n","Epoch 92/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8701 - loss: 0.5017\n","Epoch 93/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8695 - loss: 0.5002\n","Epoch 94/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8702 - loss: 0.4963\n","Epoch 95/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8685 - loss: 0.4996\n","Epoch 96/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8695 - loss: 0.4943\n","Epoch 97/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8713 - loss: 0.4894\n","Epoch 98/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8708 - loss: 0.4901\n","Epoch 99/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8721 - loss: 0.4879\n","Epoch 100/100\n","\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.8737 - loss: 0.4796\n","\n","--- Bi-LSTM Training Complete! ---\n"]}]},{"cell_type":"code","source":["# The prediction function needs to be updated to use the new_model\n","def predict_next_word_improved(seed_text, n_words=1):\n","    \"\"\"\n","    Predicts the next n_words given a seed text using the IMPROVED Bi-LSTM model.\n","    \"\"\"\n","    input_len = X.shape[1]\n","\n","    for _ in range(n_words):\n","        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n","        padded_token_list = pad_sequences([token_list], maxlen=input_len, padding='pre')\n","\n","        # *** IMPORTANT: Use new_model here ***\n","        predicted_probs = new_model.predict(padded_token_list, verbose=0)\n","\n","        predicted_index = np.argmax(predicted_probs, axis=-1)[0]\n","\n","        output_word = \"\"\n","        if predicted_index in tokenizer.index_word:\n","            output_word = tokenizer.index_word[predicted_index]\n","\n","        seed_text += \" \" + output_word\n","\n","    return seed_text.title()\n","\n","# --- Test Cases ---\n","\n","print(\"\\n--- Bi-LSTM Predictions (Accuracy 87.37%) ---\")\n","\n","# Test 1: Re-run the problematic phrase to check improvement\n","seed1 = \"the dog runs after the\"\n","print(f\"Input: '{seed1}'\\nPrediction: {predict_next_word_improved(seed1, 3)}\\n\")\n","\n","# Test 2: Dialogue test\n","seed2 = \"my dear watson\"\n","print(f\"Input: '{seed2}'\\nPrediction: {predict_next_word_improved(seed2, 5)}\\n\")\n","\n","# Test 3: Longer generation\n","seed3 = \"i could see the smoke\"\n","print(f\"Input: '{seed3}'\\nPrediction: {predict_next_word_improved(seed3, 10)}\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5dqfIJOE5pAu","executionInfo":{"status":"ok","timestamp":1764861739284,"user_tz":-330,"elapsed":1050,"user":{"displayName":"22bd1a056g","userId":"12822488165018302407"}},"outputId":"6774b5ac-5904-4194-b698-747c53b5aa92"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Bi-LSTM Predictions (Accuracy 87.37%) ---\n","Input: 'the dog runs after the'\n","Prediction: The Dog Runs After The Letter Is I\n","\n","Input: 'my dear watson'\n","Prediction: My Dear Watson I See That You Was\n","\n","Input: 'i could see the smoke'\n"," That It\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Gut4PRZG9MI5"},"execution_count":null,"outputs":[]}]}